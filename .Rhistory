GDP_GDI[i, ] <- rbinorm(1,GDP$mu[i], sigma_X, GDP$mu[i],sigma_Y, rho)
}
GDP_GDI
jointDf <- as.data.frame(GDP_GDI)
names(jointDf) <- c("GDP", "GDI")
ggplot(jointDf) +
aes(GDI, GDP) +
geom_point()
with(jointDf, sd(GDI))
with(jointDf, sd(GDP))
7/3
# 2.2
# Draw 100, 000 times from the univariate normal prior for μ
# that you specified in the previous subproblem
n <- 100000
m <- 1.6
s <- .25
ind <- 1:n
# Prior Distribution
GDP <- tibble(mu = rnorm(n, m, s))
ggplot(GDP) +
geom_density(aes(x = mu ))
rbinorm <- function(n, mu_X, sigma_X, mu_Y, sigma_Y, rho) {
x <- rnorm(n, mean = mu_X, sd = sigma_X)
y <- rnorm(n, mean = mu_Y + rho * sigma_Y / sigma_X * (x - mu_X),
sd = sigma_Y * sqrt((1 + rho) * (1 - rho)))
return(cbind(x, y))
}
sigma_X <- 7/3; sigma_Y <- 7/3; rho <- -1/10
GDP_GDI <- matrix(NA, nrow = n, ncol = 2)
for(i in 1:n){
GDP_GDI[i, ] <- rbinorm(1,GDP$mu[i], sigma_X, GDP$mu[i],sigma_Y, rho)
}
jointDf <- as.data.frame(GDP_GDI)
names(jointDf) <- c("GDP", "GDI")
ggplot(jointDf) +
aes(GDI, GDP) +
geom_point()
with(jointDf, sd(GDI))
with(jointDf, sd(GDP))
7/3
library(dplyr)
library(tidyr)
library(tidyverse)
rm(list = ls())
options(scipen=999)
library(dplyr)
FRED <- "https://fred.stlouisfed.org/graph/fredgraph.csv"
dataset <- readr::read_csv(paste0(FRED, "?id=A261RL1Q225SBEA,A191RL1Q225SBEA")) %>%
rename(quarter_startdate = DATE, GDI = A261RL1Q225SBEA, GDP = A191RL1Q225SBEA) %>%
arrange(desc(quarter_startdate))
head(dataset)
# 2.2
# Draw 100, 000 times from the univariate normal prior for μ
# that you specified in the previous subproblem
n <- 100000
m <- 2
s <- .25
ind <- 1:n
# Prior Distribution
GDP <- tibble(mu = rnorm(n, m, s))
ggplot(GDP) +
geom_density(aes(x = mu ))
rbinorm <- function(n, mu_X, sigma_X, mu_Y, sigma_Y, rho) {
x <- rnorm(n, mean = mu_X, sd = sigma_X)
y <- rnorm(n, mean = mu_Y + rho * sigma_Y / sigma_X * (x - mu_X),
sd = sigma_Y * sqrt((1 + rho) * (1 - rho)))
return(cbind(x, y))
}
sigma_X <- 7/3; sigma_Y <- 7/3; rho <- -1/10
GDP_GDI <- matrix(NA, nrow = n, ncol = 2)
for(i in 1:n){
GDP_GDI[i, ] <- rbinorm(1,GDP$mu[i], sigma_X, GDP$mu[i],sigma_Y, rho)
}
jointDf <- as.data.frame(GDP_GDI)
names(jointDf) <- c("GDP", "GDI")
ggplot(jointDf) +
aes(GDI, GDP) +
geom_point()
with(jointDf, sd(GDI))
with(jointDf, sd(GDP))
7/3
# 2.3
library(dplyr)
library(tidyr)
library(tidyverse)
rm(list = ls())
options(scipen=999)
library(dplyr)
FRED <- "https://fred.stlouisfed.org/graph/fredgraph.csv"
dataset <- readr::read_csv(paste0(FRED, "?id=A261RL1Q225SBEA,A191RL1Q225SBEA")) %>%
rename(quarter_startdate = DATE, GDI = A261RL1Q225SBEA, GDP = A191RL1Q225SBEA) %>%
arrange(desc(quarter_startdate))
head(dataset)
# 2.2
# Draw 100, 000 times from the univariate normal prior for μ
# that you specified in the previous subproblem
n <- 100000
m <- 1.6
s <- .4
ind <- 1:n
# Prior Distribution
GDP <- tibble(mu = rnorm(n, m, s))
ggplot(GDP) +
geom_density(aes(x = mu ))
rbinorm <- function(n, mu_X, sigma_X, mu_Y, sigma_Y, rho) {
x <- rnorm(n, mean = mu_X, sd = sigma_X)
y <- rnorm(n, mean = mu_Y + rho * sigma_Y / sigma_X * (x - mu_X),
sd = sigma_Y * sqrt((1 + rho) * (1 - rho)))
return(cbind(x, y))
}
sigma_X <- 7/3; sigma_Y <- 7/3; rho <- -1/10
GDP_GDI <- matrix(NA, nrow = n, ncol = 2)
for(i in 1:n){
GDP_GDI[i, ] <- rbinorm(1,GDP$mu[i], sigma_X, GDP$mu[i],sigma_Y, rho)
}
jointDf <- as.data.frame(GDP_GDI)
names(jointDf) <- c("GDP", "GDI")
ggplot(jointDf) +
aes(GDI, GDP) +
geom_point()
with(jointDf, sd(GDI))
with(jointDf, sd(GDP))
7/3
# 2.3
library(dplyr)
library(tidyr)
library(tidyverse)
rm(list = ls())
options(scipen=999)
library(dplyr)
FRED <- "https://fred.stlouisfed.org/graph/fredgraph.csv"
dataset <- readr::read_csv(paste0(FRED, "?id=A261RL1Q225SBEA,A191RL1Q225SBEA")) %>%
rename(quarter_startdate = DATE, GDI = A261RL1Q225SBEA, GDP = A191RL1Q225SBEA) %>%
arrange(desc(quarter_startdate))
head(dataset)
# 2.2
# Draw 100, 000 times from the univariate normal prior for μ
# that you specified in the previous subproblem
n <- 100000
m <- 2.6
s <- 1
ind <- 1:n
# Prior Distribution
GDP <- tibble(mu = rnorm(n, m, s))
ggplot(GDP) +
geom_density(aes(x = mu ))
rbinorm <- function(n, mu_X, sigma_X, mu_Y, sigma_Y, rho) {
x <- rnorm(n, mean = mu_X, sd = sigma_X)
y <- rnorm(n, mean = mu_Y + rho * sigma_Y / sigma_X * (x - mu_X),
sd = sigma_Y * sqrt((1 + rho) * (1 - rho)))
return(cbind(x, y))
}
sigma_X <- 7/3; sigma_Y <- 7/3; rho <- -1/10
GDP_GDI <- matrix(NA, nrow = n, ncol = 2)
for(i in 1:n){
GDP_GDI[i, ] <- rbinorm(1,GDP$mu[i], sigma_X, GDP$mu[i],sigma_Y, rho)
}
jointDf <- as.data.frame(GDP_GDI)
names(jointDf) <- c("GDP", "GDI")
ggplot(jointDf) +
aes(GDI, GDP) +
geom_point()
with(jointDf, sd(GDI))
with(jointDf, sd(GDP))
7/3
# 2.3
library(dplyr)
library(tidyr)
library(tidyverse)
rm(list = ls())
options(scipen=999)
library(dplyr)
FRED <- "https://fred.stlouisfed.org/graph/fredgraph.csv"
dataset <- readr::read_csv(paste0(FRED, "?id=A261RL1Q225SBEA,A191RL1Q225SBEA")) %>%
rename(quarter_startdate = DATE, GDI = A261RL1Q225SBEA, GDP = A191RL1Q225SBEA) %>%
arrange(desc(quarter_startdate))
head(dataset)
# 2.2
# Draw 100, 000 times from the univariate normal prior for μ
# that you specified in the previous subproblem
n <- 100000
m <- 2.6
s <- .7
ind <- 1:n
# Prior Distribution
GDP <- tibble(mu = rnorm(n, m, s))
ggplot(GDP) +
geom_density(aes(x = mu ))
rbinorm <- function(n, mu_X, sigma_X, mu_Y, sigma_Y, rho) {
x <- rnorm(n, mean = mu_X, sd = sigma_X)
y <- rnorm(n, mean = mu_Y + rho * sigma_Y / sigma_X * (x - mu_X),
sd = sigma_Y * sqrt((1 + rho) * (1 - rho)))
return(cbind(x, y))
}
sigma_X <- 7/3; sigma_Y <- 7/3; rho <- -1/10
GDP_GDI <- matrix(NA, nrow = n, ncol = 2)
for(i in 1:n){
GDP_GDI[i, ] <- rbinorm(1,GDP$mu[i], sigma_X, GDP$mu[i],sigma_Y, rho)
}
jointDf <- as.data.frame(GDP_GDI)
names(jointDf) <- c("GDP", "GDI")
ggplot(jointDf) +
aes(GDI, GDP) +
geom_point()
with(jointDf, sd(GDI))
with(jointDf, sd(GDP))
7/3
# 2.3
library(dplyr)
library(tidyr)
library(tidyverse)
rm(list = ls())
options(scipen=999)
library(dplyr)
FRED <- "https://fred.stlouisfed.org/graph/fredgraph.csv"
dataset <- readr::read_csv(paste0(FRED, "?id=A261RL1Q225SBEA,A191RL1Q225SBEA")) %>%
rename(quarter_startdate = DATE, GDI = A261RL1Q225SBEA, GDP = A191RL1Q225SBEA) %>%
arrange(desc(quarter_startdate))
head(dataset)
# 2.2
# Draw 100, 000 times from the univariate normal prior for μ
# that you specified in the previous subproblem
n <- 100000
m <- 1
s <- .5
ind <- 1:n
# Prior Distribution
GDP <- tibble(mu = rnorm(n, m, s))
ggplot(GDP) +
geom_density(aes(x = mu ))
rbinorm <- function(n, mu_X, sigma_X, mu_Y, sigma_Y, rho) {
x <- rnorm(n, mean = mu_X, sd = sigma_X)
y <- rnorm(n, mean = mu_Y + rho * sigma_Y / sigma_X * (x - mu_X),
sd = sigma_Y * sqrt((1 + rho) * (1 - rho)))
return(cbind(x, y))
}
sigma_X <- 7/3; sigma_Y <- 7/3; rho <- -1/10
GDP_GDI <- matrix(NA, nrow = n, ncol = 2)
for(i in 1:n){
GDP_GDI[i, ] <- rbinorm(1,GDP$mu[i], sigma_X, GDP$mu[i],sigma_Y, rho)
}
jointDf <- as.data.frame(GDP_GDI)
names(jointDf) <- c("GDP", "GDI")
ggplot(jointDf) +
aes(GDI, GDP) +
geom_point()
with(jointDf, sd(GDI))
with(jointDf, sd(GDP))
7/3
# 2.3
library(dplyr)
library(tidyr)
library(tidyverse)
rm(list = ls())
options(scipen=999)
library(dplyr)
FRED <- "https://fred.stlouisfed.org/graph/fredgraph.csv"
dataset <- readr::read_csv(paste0(FRED, "?id=A261RL1Q225SBEA,A191RL1Q225SBEA")) %>%
rename(quarter_startdate = DATE, GDI = A261RL1Q225SBEA, GDP = A191RL1Q225SBEA) %>%
arrange(desc(quarter_startdate))
head(dataset)
# 2.2
# Draw 100, 000 times from the univariate normal prior for μ
# that you specified in the previous subproblem
n <- 100000
m <- 1
s <- .7
ind <- 1:n
# Prior Distribution
GDP <- tibble(mu = rnorm(n, m, s))
ggplot(GDP) +
geom_density(aes(x = mu ))
rbinorm <- function(n, mu_X, sigma_X, mu_Y, sigma_Y, rho) {
x <- rnorm(n, mean = mu_X, sd = sigma_X)
y <- rnorm(n, mean = mu_Y + rho * sigma_Y / sigma_X * (x - mu_X),
sd = sigma_Y * sqrt((1 + rho) * (1 - rho)))
return(cbind(x, y))
}
sigma_X <- 7/3; sigma_Y <- 7/3; rho <- -1/10
GDP_GDI <- matrix(NA, nrow = n, ncol = 2)
for(i in 1:n){
GDP_GDI[i, ] <- rbinorm(1,GDP$mu[i], sigma_X, GDP$mu[i],sigma_Y, rho)
}
jointDf <- as.data.frame(GDP_GDI)
names(jointDf) <- c("GDP", "GDI")
ggplot(jointDf) +
aes(GDI, GDP) +
geom_point()
with(jointDf, sd(GDI))
with(jointDf, sd(GDP))
7/3
# 2.3
# 2.3
head(dataset)
View(dataset)
library(dplyr)
library(tidyr)
library(tidyverse)
rm(list = ls())
options(scipen=999)
library(dplyr)
FRED <- "https://fred.stlouisfed.org/graph/fredgraph.csv"
dataset <- readr::read_csv(paste0(FRED, "?id=A261RL1Q225SBEA,A191RL1Q225SBEA")) %>%
rename(quarter_startdate = DATE, GDI = A261RL1Q225SBEA, GDP = A191RL1Q225SBEA) %>%
arrange(desc(quarter_startdate))
head(dataset)
# 2.2
# Draw 100, 000 times from the univariate normal prior for μ
# that you specified in the previous subproblem
n <- 100000
m <- 2.5
s <- .7
ind <- 1:n
# Prior Distribution
GDP <- tibble(mu = rnorm(n, m, s))
ggplot(GDP) +
geom_density(aes(x = mu ))
rbinorm <- function(n, mu_X, sigma_X, mu_Y, sigma_Y, rho) {
x <- rnorm(n, mean = mu_X, sd = sigma_X)
y <- rnorm(n, mean = mu_Y + rho * sigma_Y / sigma_X * (x - mu_X),
sd = sigma_Y * sqrt((1 + rho) * (1 - rho)))
return(cbind(x, y))
}
sigma_X <- 7/3; sigma_Y <- 7/3; rho <- -1/10
GDP_GDI <- matrix(NA, nrow = n, ncol = 2)
for(i in 1:n){
GDP_GDI[i, ] <- rbinorm(1,GDP$mu[i], sigma_X, GDP$mu[i],sigma_Y, rho)
}
jointDf <- as.data.frame(GDP_GDI)
names(jointDf) <- c("GDP", "GDI")
ggplot(jointDf) +
aes(GDI, GDP) +
geom_point()
with(jointDf, sd(GDI))
with(jointDf, sd(GDP))
7/3
# 2.3
head(dataset)
View(dataset)
m
library(dplyr)
library(tidyr)
library(tidyverse)
rm(list = ls())
options(scipen=999)
library(dplyr)
FRED <- "https://fred.stlouisfed.org/graph/fredgraph.csv"
dataset <- readr::read_csv(paste0(FRED, "?id=A261RL1Q225SBEA,A191RL1Q225SBEA")) %>%
rename(quarter_startdate = DATE, GDI = A261RL1Q225SBEA, GDP = A191RL1Q225SBEA) %>%
arrange(desc(quarter_startdate))
head(dataset)
# 2.2
# Draw 100, 000 times from the univariate normal prior for μ
# that you specified in the previous subproblem
n <- 100000
m <- 2.5
s <- .7
# Prior Distribution
GDP <- tibble(mu = rnorm(n, m, s))
ggplot(GDP) +
geom_density(aes(x = mu ))
# Prior Distribution
GDP <- tibble(mu = rnorm(n, m, s))
ggplot(GDP) +
geom_density(aes(x = mu ))
rbinorm <- function(n, mu_X, sigma_X, mu_Y, sigma_Y, rho) {
x <- rnorm(n, mean = mu_X, sd = sigma_X)
y <- rnorm(n, mean = mu_Y + rho * sigma_Y / sigma_X * (x - mu_X),
sd = sigma_Y * sqrt((1 + rho) * (1 - rho)))
return(cbind(x, y))
}
sigma_X <- 7/3; sigma_Y <- 7/3; rho <- -1/10
GDP_GDI <- matrix(NA, nrow = n, ncol = 2)
for(i in 1:n){
GDP_GDI[i, ] <- rbinorm(1,GDP$mu[i], sigma_X, GDP$mu[i],sigma_Y, rho)
}
jointDf <- as.data.frame(GDP_GDI)
names(jointDf) <- c("GDP", "GDI")
ggplot(jointDf) +
aes(GDI, GDP) +
geom_point()
with(jointDf, sd(GDI))
with(jointDf, sd(GDP))
7/3
# 2.3
head(dataset)
m
# 3
install.packages('tidyquant')
install.packages("tidyquant")
install.packages("tidyquant")
library(tidyquant)
R_f <- tq_get("SGOV", from = "2020-06-01", to = "2022-04-01") %>%
filter(weekdays(date) == "Wednesday") %>%
transmute(R_f = (adjusted - lag(adjusted)) / lag(adjusted)) %>%
na.omit %>%
pull
library(dplyr)
library(tidyr)
library(tidyverse)
R_f <- tq_get("SGOV", from = "2020-06-01", to = "2022-04-01") %>%
filter(weekdays(date) == "Wednesday") %>%
transmute(R_f = (adjusted - lag(adjusted)) / lag(adjusted)) %>%
na.omit %>%
pull
library(tidyquant)
R_f <- tq_get("SGOV", from = "2020-06-01", to = "2022-04-01") %>%
filter(weekdays(date) == "Wednesday") %>%
transmute(R_f = (adjusted - lag(adjusted)) / lag(adjusted)) %>%
na.omit %>%
pull
?tq_get
R_f <- tq_get("SGOV", from = "2020-06-01", to = "2022-04-01") %>%
filter(weekdays(date) == "Wednesday") %>%
transmute(R_f = (adjusted - lag(adjusted)) / lag(adjusted)) %>%
na.omit %>%
pull
library(caret)
library(caret)
library(generics)
library(dplyr)
library(tidyr)
library(tidyverse)
rm(list = ls())
options(scipen=999)
version
version
library(tidyverse)
library(rvest)
library(readr)
library(dplyr)
library(tidyr)
library(tidyverse)
library(janitor)
rm(list = ls())
set.seed(1234)
options(scipen=999)
setwd("/Users/adrianharris/Desktop/Messy-Data-Project")
dataList <- vector("list", 16)
for(i in 1:16){
dataList[[i]] <- read.csv(paste0('Data/ComparePage/NewData',i,".csv"))
}
df <- do.call(rbind, dataList)
head(df, 4)
nrow(df)
# Checking for duplicates
#nrow(df)
#nrow(distinct(df))
#length(unique(df$Player))
#17755/2
#df <- df %>%
#distinct()
df <- df %>%
mutate(Rank = as.character(Rank),
Total.XP = as.character(Total.XP),
Level = as.character(Level))
df <- df %>%
mutate(Rank = as.numeric(gsub(",","", Rank)),
Level = as.numeric(gsub(",","", Level)),
Total.XP = as.numeric(gsub(",","", Total.XP)))
str(df)
# Distribution of Levels
# Some Skill go to 120
# Most go to 99
df %>%
filter(Level < 120) %>%
ggplot(.) +
aes(Level) +
geom_histogram()
# Distribution of Levels by Skill
df %>%
filter(Level < 120) %>%
ggplot(.) +
aes(Level) +
geom_histogram() +
facet_wrap(~Skill)
df %>%
filter(Level > 120) %>%
ggplot(.) +
aes(Level) +
geom_histogram() +
facet_wrap(~Skill)
dfwide <- df %>%
select(-Rank)
dfwide<- reshape(dfwide , idvar = "Player", timevar = "Skill", direction = "wide")
dfwide <- clean_names(dfwide)
head(dfwide)
str(dfwide)
# Liner Regression Data Check
dflevel <- dfwide %>% select(-contains("xp"))
playerOvr <- dfwide %>% select(player, total_xp_overall)
new <- dflevel %>% left_join(playerOvr)
str(new)
head(new)
mod <- lm(total_xp_overall ~. - player -level_overall, data = new)
summary(mod)
mod <- lm(total_xp_overall ~ level_atk + level_cooking, data = dfwide)
summary(mod)
df.clust <- df.fact<-  new
# EFA
library(haven)
library(factoextra)
library(psych)
for(i in 1:length(df.fact)){
df.fact[, i] <- as.numeric(df.fact[, i])
}
R = cor(df.fact, use = "complete.obs")
fa1 <- fa(df.fact, nfactors = 9, fm = "pa", rotate = "none", SMC = F)
KMO(R)
plot(fa1$e.values, type = "b", main = "Screeplot")
fa2_rotated  <- fa(r = df.fact, nfactors = 3,  fm = "pa", rotate = "varimax", SMC = F)
